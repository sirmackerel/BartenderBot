% Andrew G. West - prop_spec.tex
% Main LaTeX file for CIS400/401 Project Proposal Specification
%

\documentclass{sig-alternate}
 
\usepackage{mdwlist}
\usepackage{url}
\usepackage{graphicx}
\usepackage{float}
\usepackage[section]{placeins}
\begin{document} 

\title{BERTRAM: A Bartending Robot}

\subtitle{Dept. of CIS - Senior Design 2011-2012}
\numberofauthors{3}
\author{
\alignauthor Seth Shannin \\ \email{sshannin@seas.upenn.edu} \\ Univ. of Pennsylvania \\ Philadelphia, PA
\alignauthor Kevin Xu \\ \email{kevinxu@seas.upenn.edu} \\ Univ. of Pennsylvania \\ Philadelphia, PA
\alignauthor Dr. Camillo Jose Taylor \\ \email{cjtaylor@cis.upenn.edu} \\ Univ. of Pennsylvania \\ Philadelphia, PA}
\date{}
\maketitle

\begin{abstract}
\textit{\indent Programming a robot to autonomously perform human tasks has been a 
long-time goal of robotics. Such endeavors have typically involved heavy 
computation due to the demands of visual processing, path planning, and motor 
coordination. Human demonstration has often been used to introduce a sequence 
of moves to a robot, both in the form of direct physical manipulation of the 
robot and translating information from visual motion capture. Here we 
investigate teaching robotic motion through the development of an immersive
teleoperation system for controlling the PR2. Unlike previous attempts to
control the PR2 from a distance (`teleoperation'), we propose to also provide the
operator with an `immersive' experience by allowing the operator to experience the robot's
environment from the robot's perspective. \\
\indent We plan to evaluate the effectiveness of the system
by attempting to mix and serve drinks with a Willow Garage PR2 
humanoid robot controlled by a user of this immersive teleoperation system. Following the implementation of this system, we will then evaluate how the system can be used to allow
the PR2 (or any robot for that matter) to rapidly acquire new behavior within a specific environment. If successful, we will have demonstrated a novel and easy way for a
human operator to impart a specific movement sequence on to a robot. This paper details our progress in regards to implementing the immersive teleoperation system and our plans to use it to teach PR2.}
\end{abstract}

\section{Introduction}
\label{sec:intro}
\indent Constructing a fully autonomous and adaptive robot has been a long-time goal of robotics research.
The possibility of a robotic butler is only one of many potential applications. However, real
autonomous decision making (that is, free of direct control from a human operator) is an incredibly challenging process, for many different processes must 
be coordinated to make this possible. For instance, visual information must be done quickly and accurately to respond to 
changes in the environment, accurate path planning is needed to navigate the environment, and 
precise motor coordination is needed to manipulate the environment. There have been many different 
attempts at overcoming these challenges involved in developing an autonomous robot. \\
\indent One major type of approach 
that has been often explored involves the field of machine learning. The ability to learn can be a powerful intermediate 
step towards autonomy, since learning can allow a robot to adapt to new, unforeseen scenarios on its own. 
Teaching by human demonstration is a common approach to robot learning since it enables the 
transmission of complex behavior in a manner far easier than individually planning the movement of each motor and joint. However, choosing how exactly how the demonstrated behavior is delivered to the 
robot in such a way that it can record and reproduce that behavior is still a very challenging task.\\ 
\indent In this paper we report on our progress towards teaching the WillowGarage PR2 Robot how to mix and
serve drinks by first implementing an immersive teleoperation system for controlling the PR2. By `teleoperation', we simply mean control from
a distance. By `immersive', we mean giving the human operator the illusion of being inside the PR2. The PR2 is a humanoid robot developed by  Willow Garage~\cite{pr2} for the purpose of robotics 
research. It is omnidirectional and capable of telescoping height. What makes the PR2 especially attractive for robotics research is its pair of highly movable arms and grippers that allow grasping of many different kinds of objects. The PR2 also comes with a robust series of highly useful software development tools,
including a versatile simulator that allows developers to perform trial runs on a virtual PR2 without
risking damage to the actual robot. Institutions across the world have taught the PR2 a wide variety of human actions, such as baking 
cookies~\cite{cookies}, scanning and bagging groceries~\cite{groceries}, and fetching a sandwich from 
Subway~\cite{subway}. However, unlike these examples, we propose to teach the PR2 a new behavior not through advanced task planning, but through human
demonstration. Thanks to the University of Pennsylvania's GRASP laboratory, we have access to a real PR2 (as shown in Figure~\ref{fig:pr2_photo}) that we can use to test the implementation of our system.\\
\begin{figure}[htb] 
	\begin{center}
		\includegraphics[width=0.75\linewidth]{graspy}
	\end{center}
	%\vspace{-24pt}
	\caption{PR2 robot at the University of Pennsylvania, nicknamed `GRASPY'}
	\label{fig:pr2_photo}
\end{figure}
\indent The chief component of our teleoperation system is the Microsoft XBox Kinect sensor. This sensor provides depth information at real-time speeds
(30 frames per second), which essentially performs the computation that would have been required for stereo 
processing. Combined with various open source libraries~\cite{kinect}, the Kinect also works with 
software that provides human motion sensing and tracking, which greatly simplifies the task of capturing human body movements.
These Kinect libraries have already been used successfully in 
many projects involving real-time tracking of human motion, many examples of which can be found online~\cite{freenect}.\\
\indent We propose to use the Kinect as part of an immersive teleoperation system to teach the PR2 how to mix and pour different kinds of drinks.
The Kinect sensor provides a convenient way to capture a human demonstration of desired behavior. The captured data can be relayed to the
PR2 via ROS, an open-source Robot Operating System\cite{ros}. ROS provides a convenient framework for inter-process communication and
coordination. Processes that perform computation are visualized as nodes in a graph, with inter-process communication representing the
edges of the graph. Nodes send information to each other in the form of messages. Nodes that wish to send messages to other nodes can
`publish' to a topic, and nodes wishing to receive these messages need only to `subscribe' to these topics. ROS enables relatively short
programs to issue surprisingly sophisticated commands to the PR2, such as moving all of the arm joints to a specific position within a
specified time frame. By using ROS along with the PR2 and the Kinect, we will construct a system for operating the PR2 remoting while
giving the operator the feeling of being within the robot itself. The effectiveness of this system in teaching the PR2 new tasks will then be evaluated.\\
\indent What follows is an overview of work related to implementation of teleoperation systems and teaching robots human-like tasks. We then describe the components of our proposed immersive teleoperation system before delving into the technical implementation of each component. After this will be an evaluation of the current performance of the system and a summary of remaining work.

\section{Related Work}
\label{sec:related_work}
\indent There have been many previous teleoperation implementations for robotic systems. Kofman \textit{et al.}~\cite{robot_interface} devised a system for controlling a robotic arm via teleoperation and sending visual feedback to the user. The setup used in their work involves multiple cameras aimed at the human operator to capture 3-D information about the operator's arm movements. This data is then sent to a remote site containing the robotic arm and mapped to its joints so it can mimic the motion of the human arm. The human operator is able to see the robotic arm via cameras positioned at the remote site that send visual feeds of both the entire arm and of vision from the point of view of the tip of the robotic arm. Fortunately for us, the Kinect, when paired with ROS, provides a much simpler and less complicated setup to capture arm motion and send them to the PR2's arm. We are far from the first to implement teleoperation of a robot via the Kinect and ROS. However, our ultimate goal includes not only developing an immersive teleoperation system for the PR2, but also seeing how this system can be used to teach the PR2 new behavior, such as mixing and serving drinks.\\ 
\indent Other institutions have conducted research involving autonomous robots and handling drinks. Hillenbrand \textit{et al.}~\cite{pouring_arm} designed a semi-autonomous hand-arm robot for this purpose. The hand-arm was capable of responding to user input by choosing a drink from a variety of different containers, opening the drink if necessary, pouring the liquid into a glass, and then offering the drink to the user. It was capable of not only picking up bottles and cups, but also of unscrewing bottle caps. Processing of visual data from cameras was combined with object recognition to identify the drinks, after which grasp planning was used to actually pick up and manipulate the drink. Srinivasa \textit{et al.}~\cite{herb} designed an autonomous robot capable of navigating a household-like environment and manipulating a wide variety of everyday objects. Consisting of an arm mounted on a segway, HERB used a powerful array of six multi-core processors to successfully traverse its environment and interact with objects around it, such as cups and drawers. By combining different processes for object recognition, task based planning, and caged grasping, HERB was able to autonomously carry out commands issued from a graphical user interface to perform simple kitchen tasks, such as placing an object in a recycling bin or lifting a mug. The approach taken to teach by both of these works relies primarily on heavy amounts of computation to carefully plan each action that the robot will execute ahead of time.  The chief difference in our system is that we intend to teach a robot to do these kinds of things more quickly and naturally by having a human operator of our teleoperatin system execute the actions first.\\
\indent There has also been substantial work done in teaching the PR2 robot to perform various human tasks. Bohren \textit{et al.}~\cite{beer} used the PR2 and ROS to build a robotic system for retrieving a beer from a refrigerator. In their work, they developed a task-level execution system for rapidly prototyping different robotic applications. The PR2 had to navigate an obstacle map to reach the refrigerator, use object recognition and grasp planning to identify the door handle and the drinks, and ultimately use facial recognition to deliver the beer to a human recipient. Each step of the process contained detail planning and image processing in order to carry out the expected behavior. Klingbeil \textit{et al.}~\cite{groceries} developed a grasping algorithm to enable the PR2 to pick up objects and attempt to locate and scan the barcode. Their technique allowed the PR2 to devise a plan to grasp the object from only a single 3D snapshot. Their algorithm emphasized the importance of positiong the PR2's gripper such that its shape most closely matched the shape of the object it attempts to grasp. Saito \textit{et al.}~\cite{subway} devised a way for the PR2 to intelligently navigate large environments via semantic search. The PR2 attempts to find a specific object by first searching areas that would logically contain that item. When asked to retrieve a sandwich, the PR2 first inspected a nearby refrigerator in its environment. If it fails to find one there, it then determines the next most likely place a sandwich could be found. These approaches to teaching the PR2 emphasize complex algorithms used to enable the PR2 to devise a plan from scrach to act autonomously in a given environment. Our approach is simpler in that we plan to use recorded input data from our immersive teleoperation system to give the PR2 a general sequence of actions to follow that can later be refined through more complex learning techniques.\\ 
\indent There have also been other approaches involving data from human demonstration to allow a robot to perform specific tasks. In a relatively early attempt, Chalodhorn \textit{et al.}~\cite{walk_imitation} used motion capture to teach a bipedal humanoid robot how to walk by imitation. Joint angles obtained from motion capture data recorded from a human demonstrator wearing a motion capture suit were mapped to joint angles on the robot. This data was combined with predictions based on sensory information to reproduce a human-like gait in the robot. Kormushev \textit{et al.}~\cite{whiteboard} taught a robot new motor skills through kinesthetic teaching, which is teaching by physical contact. The robot had two distinct modes of operation: a learning phase and a reproduction phase. First, the robot was shown how to clean a whiteboard by direct human manipulation of the robot's joints, recording both position and force information. Subsequently, the robot would translate the learned information to its own frame of reference and attempt to duplicate the teacher's movement pattern on the whiteboard.  Kormushev \textit{et al.}~\cite{pancakes} also used kinesthetic learning to teach a robotic arm how to flip a pancake. A human teacher first moved the arm to demonstrate the movement required to flip a pancake 180 degrees in the air and catch it again. In subsequent trials, reinforcement learning techniques were applied such that the robot could evaluate the performance of its flips and attempt to adjust the motion of the arm for better future flips.\\
\indent Our method has several advantages over these existing approaches. First of all, the Kinect sensor provides accurate real-time human
motion tracking that can be mapped to specific movement in the PR2 thanks to ROS. The Kinect also provides motion capture without the need
of complicated setups involving motion capture suits or multiple cameras. Secondly, an immersive scheme for controlling the robot
enables a human operator to more naturally move the robot in a given situation compared to manipulating the robot directly by physical
contact or through a joystick-based control scheme. Immersive teleoperation also enables direct control of robots that cannot be easily
subject to demonstration through physical contact, such as very large or very small robots. Our method, if successful, would allow for rapid demonstration of different sequences of behavior to the PR2, which could be stored and queued up for later reproduction and enhancement. This technique could be generalized to other humanoid robots besides the PR2 to teach them different kinds of behavior.

\section{System Model}
Specifically because a teleimmersive system is meant to be used by human 
operators to control a robot, the external/visible part of this
design must be simple. The number of devices used to get input from the user 
and to deliver feedback should be minimal, and these devices should require
minimal effort to use. Their use should feel natural and non-intrusive.
\\
\\The design of a teleimmersive system should be simple
Although one would think that the design of a teleimmersive system should be
fairly complicated, it is actually quite surprising how modular and simple of
a system it was possible to design. This was largely enabled by ROS, the Robot
Operating System developed and supported Willow Garage. ROS follows the
publisher-subscriber model. It abstracts over hardware, I/O, and computation
services by making them visible as nodes which can send and receive messages.
\\
\\As is shown by Figure~\ref{fig:some_graph}, all communication between the 
PR2 Robot and the controlling devices must pass through ROS. In one direction,
ROS corrals the raw data from the various input devices, performs computations
on it, and then dispatches motion commands to the robot. Going in the other
direction, ROS follows the stream from the PR2's onboard video cameras and
sends the frames to the user goggles.


 there are many components
which must interact with each other to achieve teleimmersive operation.
\begin{figure}[htb] 
	\begin{center}
		\includegraphics[width=1.0\linewidth]{flowchart}
	\end{center}
	%\vspace{-24pt}
	\caption{Block Diagram Summarizing System Model}
	\label{fig:some_graph}
\end{figure}
\section{System Implementation}

\section{System Performance}
\label{subsec:eval_criteria}
We will evaluate the performance of our proposed system to teach the PR2 by experimentally determining how quickly and easily the PR2
can acquire new behavior. We will start with very simple motions, such as simply lifting and pouring a single cup or bottle. Once the PR2 is capable of completing those actions after shadowing a human demonstrator, we can attempt to teach it increasingly complex sequences of mixing and pouring. We can measure the PR2's success rate in repeating a recorded movement over multiple trials. This success rate can be then be correlated with the complexity of the demonstrated command. The goal here is to show that many different movement sequences of varying difficulty can be taught to the PR2 using the same motion capturing setup from the Kinect.\\
If time permits, we also plan to evaluate the PR2's ability to adapt to variable conditions. For instance, we can measure how far a bottle can be moved from its expected position before the PR2 becomes unable to pick it up. The weight of the bottle can also be changed to see how well the PR2 can adapt to grasping nearly-full versus nearly-empty drink containers. The success rate of the PR2's drink mixing can be analyzed as a function of these variables (distance moved, weight of drinks, etc).

\section{Remaining Work}
\label{sec:remaining_work}
The following is a list of milestones we hope to reach as the spring semester progresses.

	% The 'itemize' environment shown here, and its friend 'enumerate' (shown below), are used to create indented\bulleted\outline style lists.
\begin{itemize*}
	\item {\sc prior-to Feb.1}: Attempt real trials on the actual PR2.\vspace{3pt}
	\item {\sc prior-to Mar.1}: Achieve a simple, successful drink mixing with the PR2.\vspace{3pt}
	\item {\sc prior-to Apr.1}: Develop a more complex sequence of drink mixing with the PR2.\vspace{3pt}
	\item {\sc completion tasks}: Verify that the PR2 can successfully mix a drink. Conduct accuracy testing. Complete write-up.\vspace{3pt}
	\item {\sc if there's time} : Investigate ways to improve the PR2's ability to adapt and learn from different drink configurations.
\end{itemize*}

	% AW: We next move onto the bibliography.
\bibliographystyle{plain} % Please do not change the bib-style
\bibliography{progress_spec}  % Just the *.BIB filename

\end{document} 
